{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053c34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import nn, preprocess, io\n",
    "import numpy as np\n",
    "import pytest\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3503ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "954634b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility.\n",
    "np.random.seed(15)\n",
    "\n",
    "# Create simple neural networks for testing.\n",
    "nn_test = nn.NeuralNetwork([{'input_dim': 3, 'output_dim': 1, 'activation': 'relu'},\n",
    "                            {'input_dim': 1, 'output_dim': 3, 'activation': 'relu'}\n",
    "                            ],\n",
    "                            lr = 0.1,\n",
    "                            seed = 15,\n",
    "                            batch_size = 1,\n",
    "                            epochs = 1,\n",
    "                            loss_function = 'mse'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b9665",
   "metadata": {},
   "source": [
    "Forward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a94e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single forward pass.\n",
    "\n",
    "\n",
    "A_curr, Z_curr = nn_test._single_forward(np.array( [[30, 40, 30, 20]] ),\n",
    "                                         np.array( [[1]] ),\n",
    "                                         np.array( [1, 2, 3, 4] ),\n",
    "                                         'relu')\n",
    "\n",
    "# Assert single forward equals manually calculated values.\n",
    "assert A_curr == np.array( [[281]] )\n",
    "assert Z_curr == np.array( [281] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0a981ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete forward pass.\n",
    "# Create own inputs and assess that forward pass is calculating as expected.\n",
    "# Create own inputs and assess that forward pass is calculating as expected.\n",
    "nn_test._param_dict = {\"b1\": np.array([[1], [2]]),\n",
    "                           \"W1\": np.array([[1, 2, 3, 4], [4, 3, 2, 1]]),\n",
    "                           \"b2\": np.array([[1]]),\n",
    "                           \"W2\": np.array([[1, 4]]),\n",
    "                           }\n",
    "    \n",
    "# Perform a forward pass.\n",
    "y_hat, cache = nn_test.forward(np.array([1, 2, 3, 4]))\n",
    "assert y_hat == np.array( [[120]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00ea1e",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8e74742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate y and y_hat. Manual calculation is \n",
    "y = np.array( [0, 1, 1, 1, 0] )\n",
    "y_hat = np.array( [0, 1, 1, 0, 1] )\n",
    "\n",
    "# Instantiate mse calculated by implementation.\n",
    "mse_method = nn_test._mean_squared_error(y, y_hat)\n",
    "\n",
    "# Manual calculation of backprop is an array of errors depending on differences in y and y_hat.\n",
    "mse_bprop = np.array( [ 0. ,  0. ,  0. , -0.4,  0.4] )\n",
    "\n",
    "# Instantiate mse backprop calculated by implementation.\n",
    "mse_bprop_method = nn_test._mean_squared_error_backprop(y, y_hat)\n",
    "\n",
    "# Assert that method mse backprop matches manual calculation.\n",
    "assert np.all(mse_bprop == mse_bprop_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a01029b",
   "metadata": {},
   "source": [
    "BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d28dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08,  0.  ,  0.  , -0.08,  0.  ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate y and y_hat. Manual calculation is \n",
    "y = np.array( [0.5, 0.5, 0.4, 0.5, 0.4] )\n",
    "y_hat = np.array( [0.4, 0.5, 0.4, 0.4, 0.4] )\n",
    "\n",
    "# Instantiate mse calculated by implementation.\n",
    "bce_method = nn_test._binary_cross_entropy(y, y_hat)\n",
    "\n",
    "# Manual calculation of backprop is an array of errors depending on differences in y and y_hat.\n",
    "bce_bprop = np.array( [-0.08, 0.0, 0.0, -0.08, 0.0] )\n",
    "\n",
    "# Instantiate mse backprop calculated by implementation.\n",
    "bce_bprop_method = nn_test._binary_cross_entropy_backprop(y, y_hat)\n",
    "\n",
    "# Round bce_prop_method values.\n",
    "round_bce_bprop_method = [round(i, 2) for i in bce_bprop_method]\n",
    "\n",
    "# Assert that method mse backprop matches manual calculation.\n",
    "assert np.all(bce_bprop == np.array(round_bce_bprop_method) )\n",
    "bce_bprop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817ef99",
   "metadata": {},
   "source": [
    "Sampled_seqs unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e76800",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A', 'T', 'C', 'G']\n",
    "seqs = []\n",
    "\n",
    "# Create list of unbalanced sequences and corresponding labels.\n",
    "for seq in range(1000):\n",
    "    seq = []\n",
    "    for char in range(17):\n",
    "        seq += np.random.choice(alphabet)\n",
    "    seqs += [seq]\n",
    "\n",
    "labels = [True for lab in range(800)] + [False for x in range(200)]\n",
    "\n",
    "# Perform balanced sampling.\n",
    "sampled_seqs, sampled_labels = preprocess.sample_seqs(seqs, labels)\n",
    "\n",
    "# Create separate lists for sampled labels.\n",
    "pos_labs = []\n",
    "neg_labs = []\n",
    "for lab in sampled_labels:\n",
    "    if lab == True:\n",
    "        pos_labs += [lab]\n",
    "    else:\n",
    "        neg_labs += [lab]\n",
    "\n",
    "# Assert that sampled sequences + labels are same size as original lists.\n",
    "assert len(seqs) == len(sampled_seqs), 'Sampled sequences do not match original list length.'\n",
    "assert len(labels) == len(sampled_labels), 'Sampled labels do not match original list length.'\n",
    "\n",
    "# Assert that positive and sequences are relatively balanced (0.5 error) based on length of their sampled lists.\n",
    "assert abs( len(pos_labs) - len(neg_labs) ) < 50, 'Classes are not balanced after sampling.' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f014a",
   "metadata": {},
   "source": [
    "One_hot_encode unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c32d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = ['ATCG',\n",
    "        'GCTA']\n",
    "\n",
    "actual_encodings = np.array( [[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "                              [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0]]\n",
    "                           )\n",
    "\n",
    "encoded_seqs = preprocess.one_hot_encode_seqs(seqs)\n",
    "\n",
    "assert np.all(actual_encodings == encoded_seqs), 'One-hot encoding is not outputting the expected sequence encoding.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
